{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58112bf5",
      "metadata": {
        "id": "58112bf5"
      },
      "outputs": [],
      "source": [
        "# --- 1. Import Libraries ---\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "import random\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pv1G3b8XrJZ4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv1G3b8XrJZ4",
        "outputId": "8dcadf46-5a23-4af1-92b9-532c7b0e0d76"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation_models_pytorch\n",
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42556f0",
      "metadata": {
        "id": "c42556f0"
      },
      "outputs": [],
      "source": [
        "# --- Function to seed everything for reproducibility ---\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i2UXkXRxqDgU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2UXkXRxqDgU",
        "outputId": "0bc44a1c-d631-46fc-9ec3-53cea221fc14"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# --- 1. CONFIGURE YOUR PATHS ---\n",
        "IMAGE_PATH = '/content/drive/MyDrive/200_AD_CN_MCI_11112025/images/'\n",
        "MASK_PATH = '/content/drive/MyDrive/200_AD_CN_MCI_11112025/masks/'\n",
        "OUTPUT_CSV_PATH = '/content/drive/MyDrive/200_AD_CN_MCI_11112025/metadata.csv'\n",
        "\n",
        "# --- 2. THE \"ADVANCED NATURAL SORT\" KEY FUNCTION ---\n",
        "# This version correctly handles both text and numbers for perfect sorting.\n",
        "def advanced_natural_sort_key(filename):\n",
        "    \"\"\"\n",
        "    Creates a sort key that handles text prefixes and numbers in parenthesis.\n",
        "    Sorts first by the text part, then by the number.\n",
        "    e.g., 'ad_image_0001 (10).png' comes after 'ad_image_0001 (2).png'\n",
        "    and 'cn_image_0001 (1).png' comes after all 'ad_image_0001' files.\n",
        "    \"\"\"\n",
        "    # Find the number in parenthesis\n",
        "    match = re.search(r'\\((\\d+)\\)', filename)\n",
        "    if match:\n",
        "        # The number is our primary numeric sort key\n",
        "        number = int(match.group(1))\n",
        "        # The text part before the number is our primary text sort key\n",
        "        prefix = filename[:match.start()]\n",
        "        return (prefix, number)\n",
        "    else:\n",
        "        # If no number is found, sort by the whole filename\n",
        "        return (filename, 0)\n",
        "\n",
        "# --- 3. THE MAIN SCRIPT ---\n",
        "\n",
        "def create_parallel_metadata():\n",
        "    print(\"--- Starting Metadata Creation ---\")\n",
        "\n",
        "    try:\n",
        "        image_files = [f for f in os.listdir(IMAGE_PATH) if f.endswith('.png')]\n",
        "        mask_files = [f for f in os.listdir(MASK_PATH) if f.endswith('.png')]\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"ERROR: A directory was not found! {e}\")\n",
        "        return\n",
        "\n",
        "    # --- CRITICAL STEP: Sort both lists using the ADVANCED natural sort key ---\n",
        "    image_files.sort(key=advanced_natural_sort_key)\n",
        "    mask_files.sort(key=advanced_natural_sort_key)\n",
        "\n",
        "    print(f\"Found and sorted {len(image_files)} images.\")\n",
        "    print(f\"Found and sorted {len(mask_files)} masks.\")\n",
        "\n",
        "    # --- Validation Step ---\n",
        "    if len(image_files) != len(mask_files):\n",
        "        print(\"\\n--- FATAL ERROR: MISMATCH IN FILE COUNTS! ---\")\n",
        "        return\n",
        "\n",
        "    if not image_files:\n",
        "        print(\"\\n--- ERROR: No image files found. ---\")\n",
        "        return\n",
        "\n",
        "    # --- Create the pairs and the DataFrame ---\n",
        "    file_pairs = [{'image_id': img, 'mask_id': mask} for img, mask in zip(image_files, mask_files)]\n",
        "    metadata_df = pd.DataFrame(file_pairs)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    metadata_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
        "\n",
        "    print(f\"\\n--- SUCCESS! ---\")\n",
        "    print(f\"Created metadata.csv with {len(metadata_df)} perfectly matched pairs.\")\n",
        "    print(f\"File saved to: {OUTPUT_CSV_PATH}\")\n",
        "\n",
        "    print(\"\\n--- Here is a sample of your CORRECT metadata.csv: ---\")\n",
        "    print(\"--- Top 5 rows: ---\")\n",
        "    print(metadata_df.head())\n",
        "    print(\"\\n--- Bottom 5 rows: ---\")\n",
        "    print(metadata_df.tail())\n",
        "\n",
        "# --- Run the main function ---\n",
        "create_parallel_metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ilMtC1sYqIjM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilMtC1sYqIjM",
        "outputId": "1cfe851a-7f87-481b-a86f-3b5acdf4ae06"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae88ec1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ae88ec1",
        "outputId": "ef2fcd68-b5a5-44d4-849c-2075dd75b5eb"
      },
      "outputs": [],
      "source": [
        "# --- 2. Define Parameters and Paths ---\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "IMAGE_PATH = '/content/drive/MyDrive/200_AD_CN_MCI_11112025/images/'\n",
        "MASK_PATH = '/content/drive/MyDrive/200_AD_CN_MCI_11112025/masks/'\n",
        "METADATA_PATH = '/content/drive/MyDrive/200_AD_CN_MCI_11112025/metadata.csv'\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 200\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "ENCODER = 'resnext50_32x4d'\n",
        "PRETRAINED_WEIGHTS = 'imagenet'\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d94b2e61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d94b2e61",
        "outputId": "4ba603bb-f84a-4feb-e631-d90256830acc"
      },
      "outputs": [],
      "source": [
        "# --- 3. Data Loading and Splitting (Train-Val-Test) ---\n",
        "metadata_df = pd.read_csv(METADATA_PATH)\n",
        "train_val_df, test_df = train_test_split(metadata_df, test_size=0.15, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n",
        "\n",
        "print(f\"Total images: {len(metadata_df)}\")\n",
        "print(f\"Training images: {len(train_df)}\")\n",
        "print(f\"Validation images: {len(val_df)}\")\n",
        "print(f\"Testing images: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9865669b",
      "metadata": {
        "id": "9865669b"
      },
      "outputs": [],
      "source": [
        "# --- 4. Augmentations and PyTorch Dataset ---\n",
        "train_augs = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Affine(scale=(0.9, 1.1), translate_percent=(-0.06, 0.06), rotate=(-20, 20), p=0.7),\n",
        "    A.ElasticTransform(p=0.4, alpha=100, sigma=120 * 0.05),\n",
        "    A.GridDistortion(p=0.4),\n",
        "    A.RandomBrightnessContrast(p=0.4),\n",
        "    A.GaussNoise(p=0.2),\n",
        "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_augs = A.Compose([A.Normalize(mean=(0.5,), std=(0.5,)), ToTensorV2()])\n",
        "\n",
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, mask_dir, augmentations=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.augmentations = augmentations\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = os.path.join(self.image_dir, row['image_id'])\n",
        "        mask_path = os.path.join(self.mask_dir, row['mask_id'])\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH))\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.resize(mask, (IMG_HEIGHT, IMG_WIDTH))\n",
        "        image = np.expand_dims(image, axis=-1)\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "        if self.augmentations:\n",
        "            transformed = self.augmentations(image=image, mask=mask)\n",
        "            image = transformed['image']\n",
        "            mask = transformed['mask']\n",
        "        mask = mask / 255.0\n",
        "        mask[mask > 0.5] = 1.0\n",
        "        mask[mask <= 0.5] = 0.0\n",
        "        return image, mask.permute(2, 0, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb4f9a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fb4f9a7",
        "outputId": "cc7258e3-edbc-420b-f69a-c63a429b068e"
      },
      "outputs": [],
      "source": [
        "# --- 5. Create Datasets and DataLoaders ---\n",
        "train_dataset = BrainMRIDataset(train_df, IMAGE_PATH, MASK_PATH, augmentations=train_augs)\n",
        "val_dataset = BrainMRIDataset(val_df, IMAGE_PATH, MASK_PATH, augmentations=val_augs)\n",
        "test_dataset = BrainMRIDataset(test_df, IMAGE_PATH, MASK_PATH, augmentations=val_augs)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "print(\"DataLoaders created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ec7654",
      "metadata": {
        "id": "48ec7654"
      },
      "outputs": [],
      "source": [
        "# --- 6. Loss Function and Metrics ---\n",
        "class TverskyLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.7, beta=0.3, smooth=1e-6):\n",
        "        super(TverskyLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.smooth = smooth\n",
        "    def forward(self, inputs, targets):\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "        inputs, targets = inputs.view(-1), targets.view(-1)\n",
        "        true_pos = (inputs * targets).sum()\n",
        "        false_neg = ((1 - inputs) * targets).sum()\n",
        "        false_pos = (inputs * (1 - targets)).sum()\n",
        "        tversky_index = (true_pos + self.smooth) / (true_pos + self.alpha * false_neg + self.beta * false_pos + self.smooth)\n",
        "        return 1 - tversky_index\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.8, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha, self.gamma, self.reduction = alpha, gamma, reduction\n",
        "    def forward(self, inputs, targets):\n",
        "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-bce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt)**self.gamma * bce_loss\n",
        "        return focal_loss.mean() if self.reduction == 'mean' else focal_loss\n",
        "\n",
        "class WeightedFocalTverskyLoss(nn.Module):\n",
        "    def __init__(self, focal_weight=0.8, tversky_weight=0.2):\n",
        "        super(WeightedFocalTverskyLoss, self).__init__()\n",
        "        self.focal_loss = FocalLoss()\n",
        "        self.tversky_loss = TverskyLoss()\n",
        "        self.focal_weight, self.tversky_weight = focal_weight, tversky_weight\n",
        "    def forward(self, inputs, targets):\n",
        "        return self.focal_weight * self.focal_loss(inputs, targets) + self.tversky_weight * self.tversky_loss(inputs, targets)\n",
        "\n",
        "class BCEFocalTverskyLoss(nn.Module):\n",
        "    def __init__(self, bce_weight=0.5, focal_tversky_weight=0.5):\n",
        "        super(BCEFocalTverskyLoss, self).__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss() # More stable than Sigmoid + BCE\n",
        "        self.focal_tversky_loss = WeightedFocalTverskyLoss()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.focal_tversky_weight = focal_tversky_weight\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        bce = self.bce_loss(inputs, targets)\n",
        "        focal_tversky = self.focal_tversky_loss(inputs, targets)\n",
        "        return self.bce_weight * bce + self.focal_tversky_weight * focal_tversky\n",
        "\n",
        "def dice_coef(y_pred, y_true, smooth=1):\n",
        "    y_pred_sig = torch.sigmoid(y_pred)\n",
        "    intersection = (y_pred_sig.view(-1) * y_true.view(-1)).sum()\n",
        "    return (2. * intersection + smooth) / (y_pred_sig.sum() + y_true.sum() + smooth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef787ecf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "d03710878d55446a9752f2b0dd14e2e2",
            "3115f62f529445079cdd8ba4e489231e",
            "111d3aaf9fc943e98e33e57bd30b18a3",
            "08393e1f42ee4a9791627b72da638065",
            "fe720a327f02474eb4bc48a4550a2759",
            "55cb9d7ae9e14a5eb625223ae2d91acc",
            "a14ea6c86d294bf5b77395eb81ffa560",
            "66b3ef2c3e1f49fba556df16b6c381f4",
            "fe93746de25c4ddda7789b9556af81d3",
            "86028f826f0b46e9a2f1b8b39a13b613",
            "a0da94cd6e784af9a5c60660672eada2",
            "39268e64715b4a30ba0fa334324855c4",
            "5307d4b6cfd54246a9fcef41287b1492",
            "c4dd613857e24d5a8e73e76157da55e7",
            "89f00f7d765842959cd7cfdc77c11b28",
            "d0c1067a9ef54d2ba7ede14edb233a1a",
            "1d87737c71b341a997c55cf4f46b6082",
            "b2f36824e5954a91ba1127a0e62a8d47",
            "20daa21b34a14ea7bca7ee93903a8a7f",
            "e3c940cdb5534b158d18514a70bed159",
            "a23f5e1b12844e29a5235934fe177408",
            "ca724907a3c04d10bac6470a8fee567c"
          ]
        },
        "id": "ef787ecf",
        "outputId": "2f046386-dd52-44cd-ca53-07b4aef4cd80"
      },
      "outputs": [],
      "source": [
        "# --- 7. The Model ---\n",
        "model = smp.UnetPlusPlus(encoder_name=ENCODER, encoder_weights=PRETRAINED_WEIGHTS, in_channels=1, classes=1).to(DEVICE)\n",
        "print(f\"Model created with a pre-trained {ENCODER} encoder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec0b7395",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec0b7395",
        "outputId": "4a315771-4a94-4f70-d844-29d6fe45a1df"
      },
      "outputs": [],
      "source": [
        "# --- 8. The Training Loop (with TQDM progress bars) ---\n",
        "from tqdm import tqdm # Make sure to import tqdm\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15)\n",
        "loss_fn = BCEFocalTverskyLoss()\n",
        "\n",
        "# Early Stopping parameters\n",
        "patience = 30\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "history = {'train_loss': [], 'val_loss': [], 'train_dice': [], 'val_dice': []}\n",
        "\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss, train_dice = 0.0, 0.0\n",
        "\n",
        "    # --- Training Phase with TQDM ---\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
        "    for images, masks in loop:\n",
        "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_dice += dice_coef(outputs, masks).item()\n",
        "\n",
        "        # Update the progress bar with the current loss\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    avg_train_dice = train_dice / len(train_loader)\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['train_dice'].append(avg_train_dice)\n",
        "\n",
        "    # --- Validation Phase with TQDM ---\n",
        "    model.eval()\n",
        "    val_loss, val_dice = 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\")\n",
        "        for images, masks in loop:\n",
        "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, masks)\n",
        "            val_loss += loss.item()\n",
        "            val_dice += dice_coef(outputs, masks).item()\n",
        "\n",
        "            # Update the progress bar with the current loss\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    avg_val_dice = val_dice / len(val_loader)\n",
        "    history['val_loss'].append(avg_val_loss)\n",
        "    history['val_dice'].append(avg_val_dice)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}: Train Loss: {avg_train_loss:.4f}, Train Dice: {avg_train_dice:.4f} | Val Loss: {avg_val_loss:.4f}, Val Dice: {avg_val_dice:.4f}\")\n",
        "\n",
        "    # Step the scheduler based on validation loss\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Early Stopping and Model Saving\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), 'best_segmentation_model.pth')\n",
        "        print(\"   -> Model saved (best validation loss)\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"--- Early stopping triggered ---\")\n",
        "            break\n",
        "\n",
        "print(\"\\n--- MODEL TRAINING COMPLETE ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21189fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f21189fb",
        "outputId": "4b6b66d8-3865-42e5-b98b-c2137fdcf195"
      },
      "outputs": [],
      "source": [
        "# --- 9. Final Evaluation on the Test Set (with TQDM progress bar) ---\n",
        "from tqdm import tqdm # Make sure tqdm is imported\n",
        "\n",
        "print(\"\\n--- Evaluating on the Test Set ---\")\n",
        "\n",
        "# Load the best performing model from training\n",
        "model.load_state_dict(torch.load('best_segmentation_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0.0\n",
        "test_dice = 0.0\n",
        "with torch.no_grad():\n",
        "    # Wrap the test_loader with tqdm\n",
        "    loop = tqdm(test_loader, desc=\"Testing\")\n",
        "    for images, masks in loop:\n",
        "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = loss_fn(outputs, masks)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        dice_score = dice_coef(outputs, masks).item()\n",
        "        test_dice += dice_score\n",
        "\n",
        "        # Update the progress bar with the current metrics\n",
        "        loop.set_postfix(loss=loss.item(), dice=dice_score)\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "avg_test_dice = test_dice / len(test_loader)\n",
        "\n",
        "print(f\"\\nFinal Test Set Performance:\")\n",
        "print(f\"   - Test Loss: {avg_test_loss:.4f}\")\n",
        "print(f\"   - Test Dice Coefficient: {avg_test_dice:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9f86393",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "f9f86393",
        "outputId": "fb1ed976-cc64-49b2-affd-9ffd47df5a7b"
      },
      "outputs": [],
      "source": [
        "# --- PLOTTING TRAINING HISTORY ---\n",
        "\n",
        "print(\"\\n--- Plotting Training and Validation History ---\")\n",
        "\n",
        "# The 'history' dictionary was populated during the training loop\n",
        "train_loss = history['train_loss']\n",
        "val_loss = history['val_loss']\n",
        "train_dice = history['train_dice']\n",
        "val_dice = history['val_dice']\n",
        "\n",
        "# Get the number of epochs the model actually ran for\n",
        "# This is important if early stopping was triggered\n",
        "epochs_ran = range(1, len(train_loss) + 1)\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid') # Using a nice style for the plots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# --- Plot 1: Loss (Training vs. Validation) ---\n",
        "ax1.plot(epochs_ran, train_loss, 'b-o', label='Training Loss')\n",
        "ax1.plot(epochs_ran, val_loss, 'r-o', label='Validation Loss')\n",
        "ax1.set_title('Training & Validation Loss', fontsize=16)\n",
        "ax1.set_xlabel('Epochs', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.legend(fontsize=12)\n",
        "ax1.grid(True)\n",
        "\n",
        "# --- Plot 2: Dice Coefficient (Training vs. Validation) ---\n",
        "ax2.plot(epochs_ran, train_dice, 'b-o', label='Training Dice Coefficient')\n",
        "ax2.plot(epochs_ran, val_dice, 'r-o', label='Validation Dice Coefficient')\n",
        "ax2.set_title('Training & Validation Dice Coefficient', fontsize=16)\n",
        "ax2.set_xlabel('Epochs', fontsize=12)\n",
        "ax2.set_ylabel('Dice Coefficient', fontsize=12)\n",
        "ax2.legend(fontsize=12)\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Load the best model for evaluation (this line might already be in your next cell)\n",
        "# It's good practice to explicitly load it here before the test evaluation.\n",
        "print(\"\\n--- Best Model Weights Loaded for Final Evaluation ---\")\n",
        "model.load_state_dict(torch.load('best_segmentation_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87f7b367",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "87f7b367",
        "outputId": "6750c8c2-09e2-4977-cabc-13258496769b"
      },
      "outputs": [],
      "source": [
        "# --- 10. Visualization on Test Samples (with Post-Processing) ---\n",
        "\n",
        "print(\"\\n--- Visualizing Sample Predictions from the Test Set ---\")\n",
        "num_samples_to_show = 10\n",
        "# Ensure we don't try to show more samples than exist in the test set\n",
        "num_samples_to_show = min(num_samples_to_show, len(test_dataset))\n",
        "indices = np.random.choice(range(len(test_dataset)), num_samples_to_show, replace=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i in indices:\n",
        "        # Get a single image and mask from the test dataset\n",
        "        test_img_tensor, ground_truth_tensor = test_dataset[i]\n",
        "\n",
        "        # The model expects a batch dimension, so add it: (C, H, W) -> (B, C, H, W)\n",
        "        test_img_input = test_img_tensor.unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        # Make the prediction\n",
        "        prediction_prob = torch.sigmoid(model(test_img_input)).squeeze(0)\n",
        "\n",
        "        # Apply threshold to get the raw predicted mask\n",
        "        predicted_mask = (prediction_prob > 0.5).cpu().numpy().squeeze()\n",
        "\n",
        "        # --- START of ADDED post-processing code ---\n",
        "        # Convert to a format cv2 can use (0-255)\n",
        "        cleaned_mask_np = (predicted_mask * 255).astype(np.uint8)\n",
        "\n",
        "        # Define a kernel for morphological operations. A 3x3 or 5x5 kernel is common.\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "        # Remove small noise/speckles (Opening = erosion then dilation)\n",
        "        cleaned_mask_np = cv2.morphologyEx(cleaned_mask_np, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "\n",
        "        # Fill small holes in the main object (Closing = dilation then erosion)\n",
        "        cleaned_mask_np = cv2.morphologyEx(cleaned_mask_np, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "\n",
        "        # Convert back to 0-1 float range for consistency if needed, though imshow handles 0-255 fine\n",
        "        # For plotting, the uint8 version is fine.\n",
        "        # --- END of ADDED post-processing code ---\n",
        "\n",
        "\n",
        "        # Convert original tensors to numpy arrays for plotting\n",
        "        test_img_np = test_img_tensor.numpy().squeeze()\n",
        "        ground_truth_np = ground_truth_tensor.numpy().squeeze()\n",
        "\n",
        "        # --- Plot the results ---\n",
        "        plt.figure(figsize=(18, 6))\n",
        "\n",
        "        plt.subplot(1, 4, 1)\n",
        "        plt.title('Testing Image')\n",
        "        plt.imshow(test_img_np, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 4, 2)\n",
        "        plt.title('Ground Truth Mask')\n",
        "        plt.imshow(ground_truth_np, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 4, 3)\n",
        "        plt.title(\"Model's Raw Prediction\")\n",
        "        # Show the original, raw prediction before cleaning\n",
        "        plt.imshow(predicted_mask, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 4, 4)\n",
        "        plt.title(\"Cleaned Predicted Mask\") # <-- Changed title\n",
        "        # Show the new, cleaned mask\n",
        "        plt.imshow(cleaned_mask_np, cmap='gray') # <-- Use the cleaned mask\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2dd4442",
      "metadata": {
        "id": "d2dd4442",
        "outputId": "c0734289-92e9-466e-aea4-fd1a2f1c2100"
      },
      "outputs": [],
      "source": [
        "# --- 10. Visualization on Test Samples ---\n",
        "print(\"\\n--- Visualizing Sample Predictions from the Test Set ---\")\n",
        "num_samples_to_show = min(5, len(test_dataset))\n",
        "indices = np.random.choice(range(len(test_dataset)), num_samples_to_show, replace=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i in indices:\n",
        "        img_tensor, gt_tensor = test_dataset[i]\n",
        "        img_input = img_tensor.unsqueeze(0).to(DEVICE)\n",
        "        pred_prob = torch.sigmoid(model(img_input)).squeeze(0)\n",
        "        pred_mask = (pred_prob > 0.5).cpu().numpy().squeeze()\n",
        "        img_np, gt_np = img_tensor.numpy().squeeze(), gt_tensor.numpy().squeeze()\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title('Testing Image')\n",
        "        plt.imshow(img_np, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title('Ground Truth Mask')\n",
        "        plt.imshow(gt_np, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(\"Model's Predicted Mask\")\n",
        "        plt.imshow(pred_mask, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08393e1f42ee4a9791627b72da638065": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86028f826f0b46e9a2f1b8b39a13b613",
            "placeholder": "​",
            "style": "IPY_MODEL_a0da94cd6e784af9a5c60660672eada2",
            "value": " 134/134 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "111d3aaf9fc943e98e33e57bd30b18a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66b3ef2c3e1f49fba556df16b6c381f4",
            "max": 134,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe93746de25c4ddda7789b9556af81d3",
            "value": 134
          }
        },
        "1d87737c71b341a997c55cf4f46b6082": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20daa21b34a14ea7bca7ee93903a8a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3115f62f529445079cdd8ba4e489231e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55cb9d7ae9e14a5eb625223ae2d91acc",
            "placeholder": "​",
            "style": "IPY_MODEL_a14ea6c86d294bf5b77395eb81ffa560",
            "value": "config.json: 100%"
          }
        },
        "39268e64715b4a30ba0fa334324855c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5307d4b6cfd54246a9fcef41287b1492",
              "IPY_MODEL_c4dd613857e24d5a8e73e76157da55e7",
              "IPY_MODEL_89f00f7d765842959cd7cfdc77c11b28"
            ],
            "layout": "IPY_MODEL_d0c1067a9ef54d2ba7ede14edb233a1a"
          }
        },
        "5307d4b6cfd54246a9fcef41287b1492": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d87737c71b341a997c55cf4f46b6082",
            "placeholder": "​",
            "style": "IPY_MODEL_b2f36824e5954a91ba1127a0e62a8d47",
            "value": "model.safetensors: 100%"
          }
        },
        "55cb9d7ae9e14a5eb625223ae2d91acc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b3ef2c3e1f49fba556df16b6c381f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86028f826f0b46e9a2f1b8b39a13b613": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f00f7d765842959cd7cfdc77c11b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a23f5e1b12844e29a5235934fe177408",
            "placeholder": "​",
            "style": "IPY_MODEL_ca724907a3c04d10bac6470a8fee567c",
            "value": " 100M/100M [00:01&lt;00:00, 87.9MB/s]"
          }
        },
        "a0da94cd6e784af9a5c60660672eada2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a14ea6c86d294bf5b77395eb81ffa560": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a23f5e1b12844e29a5235934fe177408": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f36824e5954a91ba1127a0e62a8d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4dd613857e24d5a8e73e76157da55e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20daa21b34a14ea7bca7ee93903a8a7f",
            "max": 100417784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3c940cdb5534b158d18514a70bed159",
            "value": 100417784
          }
        },
        "ca724907a3c04d10bac6470a8fee567c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d03710878d55446a9752f2b0dd14e2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3115f62f529445079cdd8ba4e489231e",
              "IPY_MODEL_111d3aaf9fc943e98e33e57bd30b18a3",
              "IPY_MODEL_08393e1f42ee4a9791627b72da638065"
            ],
            "layout": "IPY_MODEL_fe720a327f02474eb4bc48a4550a2759"
          }
        },
        "d0c1067a9ef54d2ba7ede14edb233a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c940cdb5534b158d18514a70bed159": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe720a327f02474eb4bc48a4550a2759": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe93746de25c4ddda7789b9556af81d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
