{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13717847,"sourceType":"datasetVersion","datasetId":8727349},{"sourceId":13804489,"sourceType":"datasetVersion","datasetId":8789703},{"sourceId":13752030,"sourceType":"datasetVersion","datasetId":8750534}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Install Dependencies\n# ==================================================================================\n!pip install -q monai\n!pip install -q segmentation_models_pytorch\nprint(\"‚úÖ Libraries Installed: MONAI, SMP, WandB\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:30:01.962695Z","iopub.execute_input":"2025-11-20T22:30:01.963007Z","iopub.status.idle":"2025-11-20T22:30:08.779733Z","shell.execute_reply.started":"2025-11-20T22:30:01.962981Z","shell.execute_reply":"2025-11-20T22:30:08.778889Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Libraries Installed: MONAI, SMP, WandB\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Configuration & Paths\n# ==================================================================================\nimport os\nimport torch\n\nCONFIG = {\n    # --- 1. GEOMETRY (The Aspect Ratio Fix) ---\n    # We pad 208 -> 240, then Resize -> 224.\n    \"IMG_SIZE\": (224, 224),\n    \"NATIVE_PAD_SIZE\": (240, 240), \n    \n    # --- 2. DATA MIXING (The Anchor Strategy) ---\n    # We want an effective batch size of 16.\n    # Since MaxViT is heavy, we might use Grad Accumulation if T4 runs OOM.\n    \"REAL_BS\": 16,       # Real images per step\n    \"PSEUDO_BS\": 16,     # Pseudo images per step\n    \"GRAD_ACCUM_STEPS\": 1, # Increase to 2 if you hit OOM (Effective BS becomes 32)\n    \n    # --- 3. TRAINING HYPERPARAMETERS ---\n    \"EPOCHS\": 20,\n    \"LR\": 1e-4,\n    \"WEIGHT_DECAY\": 1e-2, # Stronger decay for Transformers\n    \"SEED\": 42,\n    \"PRECISION\": \"amp\",   # Automatic Mixed Precision\n    \n    # --- 4. PATHS (Mapped from your Screenshot) ---\n    # Dataset 1: 200 Gold Standard\n    \"GOLD_IMG_DIR\": \"/kaggle/input/200-gold-standard-adni/200_AD_CN_MCI_11112025/images\",\n    \"GOLD_MASK_DIR\": \"/kaggle/input/200-gold-standard-adni/200_AD_CN_MCI_11112025/masks\",\n    \n    # Dataset 2: Gold Metadata\n    \"GOLD_CSV\": \"/kaggle/input/metadatafor200gd/metadata.csv\",\n    \n    # Dataset 3: Titanium (Pseudo)\n    \"TITANIUM_IMG_DIR\": \"/kaggle/input/tittanium-standard-dataset/TITANIUM_20K_DATASET/images\",\n    \"TITANIUM_MASK_DIR\": \"/kaggle/input/tittanium-standard-dataset/TITANIUM_20K_DATASET/masks\",\n    \"TITANIUM_CSV\": \"/kaggle/input/tittanium-standard-dataset/TITANIUM_20K_DATASET/metadata.csv\",\n    \n    # --- 5. LOGGING ---\n    \"PROJECT_NAME\": \"Brain_SOTA_MaxViT_AnchorUT\",\n    \"ENTITY\": \"alzhemer_segmentaion\", # Update if needed\n    \"FOLDS_TO_RUN\": [0], # Run all 5 folds for scientific validity\n    \"CACHE_RATE\": 1.0, # Cache 100% of Real data in RAM (Kaggle has plenty)\n}\n\n# Device Check\nCONFIG['DEVICE'] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"‚úÖ Configuration Loaded.\")\nprint(f\"   Target Resolution: {CONFIG['IMG_SIZE']}\")\nprint(f\"   Batch Composition: {CONFIG['REAL_BS']} Real + {CONFIG['PSEUDO_BS']} Pseudo\")\nprint(f\"   Path Check (Gold): {os.path.exists(CONFIG['GOLD_IMG_DIR'])}\")\nprint(f\"   Path Check (Titanium): {os.path.exists(CONFIG['TITANIUM_IMG_DIR'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:30:08.783176Z","iopub.execute_input":"2025-11-20T22:30:08.783501Z","iopub.status.idle":"2025-11-20T22:30:10.465832Z","shell.execute_reply.started":"2025-11-20T22:30:08.783451Z","shell.execute_reply":"2025-11-20T22:30:10.465134Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Configuration Loaded.\n   Target Resolution: (224, 224)\n   Batch Composition: 16 Real + 16 Pseudo\n   Path Check (Gold): True\n   Path Check (Titanium): True\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 3: Imports & Reproducibility\n# ==================================================================================\nimport gc\nimport sys\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import DataLoader\n\n# MONAI (The Medical Engine)\nimport monai\nfrom monai.data import Dataset, CacheDataset, DataLoader as MonaiLoader\nfrom monai.transforms import (\n    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, \n    ResizeWithPadOrCropd, Resized, RandFlipd, RandRotate90d, \n    RandShiftIntensityd, RandCoarseDropoutd, EnsureTyped, NormalizeIntensityd\n)\nfrom monai.utils import set_determinism\n\n# Model Library\nimport segmentation_models_pytorch as smp\n\n# Logging\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\n\n# 1. Set Determinism (Reproducibility)\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False # Slower but reproducible\n    set_determinism(seed=seed) # MONAI specific seed\n\nseed_everything(CONFIG['SEED'])\n\n# 2. Login to WandB\ntry:\n    user_secrets = UserSecretsClient()\n    wandb_key = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=wandb_key)\n    print(\"‚úÖ WandB Logged In\")\nexcept:\n    print(\"‚ö†Ô∏è WandB Login Failed (Check Kaggle Secrets)\")\n    wandb.login(anonymous='must')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:30:10.467655Z","iopub.execute_input":"2025-11-20T22:30:10.468040Z","iopub.status.idle":"2025-11-20T22:30:31.023689Z","shell.execute_reply.started":"2025-11-20T22:30:10.468021Z","shell.execute_reply":"2025-11-20T22:30:31.022958Z"}},"outputs":[{"name":"stderr","text":"<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n2025-11-20 22:30:16.467809: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763677816.490662     360 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763677816.497620     360 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mutkarsh3104-imp\u001b[0m (\u001b[33malzhemer_segmentaion\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ WandB Logged In\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 4: MONAI Transforms\n# ==================================================================================\ndef get_transforms(phase):\n    \"\"\"\n    Returns MONAI Compose transforms.\n    keys=[\"image\", \"mask\"] tells MONAI to apply geometry changes to BOTH,\n    but intensity changes ONLY to the image.\n    \"\"\"\n    \n    # 1. COMMON TRANSFORMS (Geometry Fix)\n    # We Pad 208 -> 240 (Square), then Downsample -> 224.\n    # This preserves the exact shape of the ventricles.\n    common_transforms = [\n        LoadImaged(keys=[\"image\", \"mask\"]),\n        EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n        \n        # --- THE GEOMETRY FIX ---\n        # Center the brain and pad with zeros to 240x240\n        ResizeWithPadOrCropd(keys=[\"image\", \"mask\"], spatial_size=CONFIG['NATIVE_PAD_SIZE']),\n        # Resize to MaxViT input (224x224)\n        Resized(keys=[\"image\", \"mask\"], spatial_size=CONFIG['IMG_SIZE'], mode=(\"bilinear\", \"nearest\")),\n        \n        # Normalize Intensity (Crucial for MRI)\n        ScaleIntensityd(keys=[\"image\"]), \n    ]\n\n    # 2. TRAINING TRANSFORMS (Augmentation)\n    if phase == 'train':\n        train_transforms = [\n            # Geometry Augs\n            RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=0),\n            RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=1),\n            RandRotate90d(keys=[\"image\", \"mask\"], prob=0.5, max_k=3),\n            \n            # Intensity Augs (Scanner Variance)\n            RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n            \n            # --- THE BIAS FIX (Spatial Dropout) ---\n            # Cut 8 holes of size 16x16. \n            # This stops MaxViT from memorizing the skull/background.\n            RandCoarseDropoutd(\n                keys=[\"image\", \"mask\"],\n                holes=8, spatial_size=(20, 20),\n                fill_value=0, prob=0.3\n            ),\n            \n            EnsureTyped(keys=[\"image\", \"mask\"])\n        ]\n        return Compose(common_transforms + train_transforms)\n\n    # 3. VALIDATION TRANSFORMS (Clean)\n    else:\n        val_transforms = [\n            EnsureTyped(keys=[\"image\", \"mask\"])\n        ]\n        return Compose(common_transforms + val_transforms)\n\nprint(\"‚úÖ Transforms Defined using MONAI (Geometry-Safe)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:30:31.024525Z","iopub.execute_input":"2025-11-20T22:30:31.025259Z","iopub.status.idle":"2025-11-20T22:30:31.034067Z","shell.execute_reply.started":"2025-11-20T22:30:31.025237Z","shell.execute_reply":"2025-11-20T22:30:31.033492Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Transforms Defined using MONAI (Geometry-Safe)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Cell 5: Custom Transforms & Data Helper (CORRECTED)\n# ==================================================================================\nfrom monai.transforms import MapTransform\n\nclass ProcessMaskd(MapTransform):\n    \"\"\"\n    Custom MONAI Transform to handle Label Types.\n    - If Real (Gold): Binarizes mask (0.0 or 1.0).\n    - If Pseudo (Titanium): Normalizes mask (0.0 to 1.0) for Soft Labels.\n    \"\"\"\n    def __init__(self, keys, is_pseudo=False):\n        super().__init__(keys)\n        self.is_pseudo = is_pseudo\n\n    def __call__(self, data):\n        d = dict(data)\n        for key in self.keys:\n            # Pseudo: Keep uncertainty (0-255 -> 0.0-1.0)\n            if self.is_pseudo:\n                d[key] = d[key].float() / 255.0\n            # Real: Hard Threshold (0-255 -> 0.0 or 1.0)\n            else:\n                d[key] = torch.where(d[key] > 127, 1.0, 0.0)\n        return d\n\ndef get_data_dicts(gold_df, pseudo_df=None, fold=0, phase='train'):\n    \"\"\"\n    Prepares list of dictionaries for MONAI Dataset.\n    Handles None inputs safely.\n    \"\"\"\n    data_dicts = []\n    \n    if phase == 'train':\n        # 1. Process Gold Data (Only if provided)\n        if gold_df is not None:\n            for _, row in gold_df.iterrows():\n                data_dicts.append({\n                    \"image\": os.path.join(CONFIG['GOLD_IMG_DIR'], row['image_id']),\n                    \"mask\": os.path.join(CONFIG['GOLD_MASK_DIR'], row['mask_id']),\n                    \"source\": \"gold\"\n                })\n            \n        # 2. Process Pseudo Data (Only if provided)\n        if pseudo_df is not None:\n            for _, row in pseudo_df.iterrows():\n                data_dicts.append({\n                    \"image\": os.path.join(CONFIG['TITANIUM_IMG_DIR'], row['image_id']),\n                    \"mask\": os.path.join(CONFIG['TITANIUM_MASK_DIR'], row['mask_id']),\n                    \"source\": \"pseudo\"\n                })\n    else:\n        # Validation List (Always Gold)\n        if gold_df is not None:\n            for _, row in gold_df.iterrows():\n                data_dicts.append({\n                    \"image\": os.path.join(CONFIG['GOLD_IMG_DIR'], row['image_id']),\n                    \"mask\": os.path.join(CONFIG['GOLD_MASK_DIR'], row['mask_id']),\n                    \"source\": \"gold\"\n                })\n            \n    return data_dicts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:30:31.035044Z","iopub.execute_input":"2025-11-20T22:30:31.035311Z","iopub.status.idle":"2025-11-20T22:30:31.056384Z","shell.execute_reply.started":"2025-11-20T22:30:31.035287Z","shell.execute_reply":"2025-11-20T22:30:31.055766Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Cell 6: Hybrid Loss & Metrics (UPDATED)\n# ==================================================================================\nfrom monai.losses import HausdorffDTLoss, DiceLoss\nfrom monai.metrics import DiceMetric, HausdorffDistanceMetric, MeanIoU\n\n# Loss (Same as before)\nclass HybridLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bce = nn.BCEWithLogitsLoss()\n        self.dice = DiceLoss(sigmoid=True, batch=True)\n        self.hausdorff = HausdorffDTLoss(sigmoid=True)\n\n    def forward(self, pred, target):\n        loss_bce = self.bce(pred, target)\n        loss_dice = self.dice(pred, target)\n        # HD is heavy, we weight it lower\n        loss_hd = self.hausdorff(pred, target)\n        return (0.4 * loss_bce) + (0.3 * loss_dice) + (0.3 * loss_hd)\n\n# --- METRICS INITIALIZATION ---\n# We need independent counters for Train and Val to avoid mixing data\ndice_metric = DiceMetric(include_background=False, reduction=\"mean\")\niou_metric = MeanIoU(include_background=False, reduction=\"mean\")\nhd_metric = HausdorffDistanceMetric(include_background=False, percentile=95, reduction=\"mean\")\n\n# Helper to calculate simple batch dice for training monitoring (faster than MONAI metric)\ndef get_batch_dice(y_pred, y_true):\n    y_pred = (y_pred.sigmoid() > 0.5).float()\n    # Threshold soft labels for metric calculation\n    y_true = (y_true > 0.5).float()\n    intersection = (y_pred * y_true).sum()\n    union = y_pred.sum() + y_true.sum()\n    return 2.0 * intersection / (union + 1e-6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:30:31.057419Z","iopub.execute_input":"2025-11-20T22:30:31.057710Z","iopub.status.idle":"2025-11-20T22:30:31.075825Z","shell.execute_reply.started":"2025-11-20T22:30:31.057687Z","shell.execute_reply":"2025-11-20T22:30:31.075034Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Cell 7: Model Builder\n# ==================================================================================\ndef build_model():\n    model = smp.UnetPlusPlus(\n        encoder_name=\"tu-maxvit_rmlp_small_rw_224\", # MaxViT Tiny (224 Native)\n        encoder_weights=\"imagenet\",\n        in_channels=1, # MONAI LoadImage usually keeps it 1 channel if greyscale\n        classes=1,\n        activation=None\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:30:31.076575Z","iopub.execute_input":"2025-11-20T22:30:31.076756Z","iopub.status.idle":"2025-11-20T22:30:31.090752Z","shell.execute_reply.started":"2025-11-20T22:30:31.076734Z","shell.execute_reply":"2025-11-20T22:30:31.089968Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Cell 8: Training Engine (FULL METRICS VERSION)\n# ==================================================================================\nfrom itertools import cycle\n\ndef train_one_epoch(model, loader_gold, loader_pseudo, optimizer, loss_fn, scaler, epoch):\n    model.train()\n    running_loss = 0\n    running_train_dice = 0 # <--- NEW: Track Train Accuracy\n    \n    iterator = tqdm(zip(cycle(loader_gold), loader_pseudo), total=len(loader_pseudo), desc=f\"Train Ep {epoch}\", leave=False)\n    \n    optimizer.zero_grad()\n    \n    for step, (batch_gold, batch_pseudo) in enumerate(iterator):\n        img_g, mask_g = batch_gold['image'].to(CONFIG['DEVICE']), batch_gold['mask'].to(CONFIG['DEVICE'])\n        img_p, mask_p = batch_pseudo['image'].to(CONFIG['DEVICE']), batch_pseudo['mask'].to(CONFIG['DEVICE'])\n        \n        images = torch.cat([img_g, img_p], dim=0)\n        masks = torch.cat([mask_g, mask_p], dim=0)\n        \n        with autocast():\n            outputs = model(images)\n            loss = loss_fn(outputs, masks)\n            loss = loss / CONFIG['GRAD_ACCUM_STEPS']\n            \n        scaler.scale(loss).backward()\n        \n        if (step + 1) % CONFIG['GRAD_ACCUM_STEPS'] == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            \n        # --- METRIC TRACKING ---\n        current_loss = loss.item() * CONFIG['GRAD_ACCUM_STEPS']\n        running_loss += current_loss\n        \n        # Calculate rough batch dice for monitoring (on GPU)\n        batch_dice = get_batch_dice(outputs.detach(), masks)\n        running_train_dice += batch_dice.item()\n        \n        # Detailed WandB Logging every 50 steps\n        if step % 50 == 0:\n            wandb.log({\n                \"train/step_loss\": current_loss,\n                \"train/step_dice\": batch_dice.item(),\n                \"train/lr\": optimizer.param_groups[0]['lr']\n            })\n            \n    epoch_loss = running_loss / len(loader_pseudo)\n    epoch_dice = running_train_dice / len(loader_pseudo)\n    return epoch_loss, epoch_dice\n\n@torch.no_grad()\ndef valid_one_epoch(model, loader, epoch):\n    model.eval()\n    dice_metric.reset()\n    hd_metric.reset()\n    iou_metric.reset() # <--- NEW\n    \n    for batch in tqdm(loader, desc=f\"Val Ep {epoch}\", leave=False):\n        images, masks = batch['image'].to(CONFIG['DEVICE']), batch['mask'].to(CONFIG['DEVICE'])\n        \n        with autocast():\n            # TTA\n            pred_1 = torch.sigmoid(model(images))\n            pred_2 = torch.sigmoid(torch.flip(model(torch.flip(images, dims=[3])), dims=[3]))\n            pred_avg = (pred_1 + pred_2) / 2.0\n            \n        pred_bin = (pred_avg > 0.5).float()\n        \n        # Update Metrics\n        dice_metric(y_pred=pred_bin, y=masks)\n        hd_metric(y_pred=pred_bin, y=masks)\n        iou_metric(y_pred=pred_bin, y=masks) # <--- NEW\n        \n    mean_dice = dice_metric.aggregate().item()\n    mean_hd = hd_metric.aggregate().item()\n    mean_iou = iou_metric.aggregate().item() # <--- NEW\n    \n    # Log Sample to WandB\n    wandb.log({\n        \"val/sample\": wandb.Image(\n            images[0].cpu().numpy().transpose(1, 2, 0),\n            masks={\n                \"pred\": {\"mask_data\": pred_bin[0,0].cpu().numpy(), \"class_labels\": {1: \"Brain\"}},\n                \"truth\": {\"mask_data\": masks[0,0].cpu().numpy(), \"class_labels\": {1: \"Brain\"}}\n            },\n            caption=f\"Epoch {epoch} Pred\"\n        )\n    })\n    \n    return mean_dice, mean_hd, mean_iou","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:30:31.091542Z","iopub.execute_input":"2025-11-20T22:30:31.092159Z","iopub.status.idle":"2025-11-20T22:30:31.111821Z","shell.execute_reply.started":"2025-11-20T22:30:31.092139Z","shell.execute_reply":"2025-11-20T22:30:31.111103Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Cell 9: K-Fold Execution (FINAL VERSION)\n# ==================================================================================\nfrom sklearn.model_selection import KFold\nimport json # Needed for report saving\n\n# Load CSVs\ngold_df = pd.read_csv(CONFIG['GOLD_CSV'])\npseudo_df = pd.read_csv(CONFIG['TITANIUM_CSV'])\n\n# Define K-Fold\nkf = KFold(n_splits=5, shuffle=True, random_state=CONFIG['SEED'])\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(gold_df)):\n    if fold not in CONFIG['FOLDS_TO_RUN']:\n        continue\n        \n    print(f\"\\nüöÄ STARTING FOLD {fold}\")\n    \n    # 1. Init WandB\n    run = wandb.init(project=CONFIG['PROJECT_NAME'], entity=CONFIG['ENTITY'], name=f\"MaxViT_Fold_{fold}\", config=CONFIG, reinit=True)\n    \n    # 2. Split Dataframes\n    train_gold_fold = gold_df.iloc[train_idx]\n    val_gold_fold = gold_df.iloc[val_idx]\n    \n    # 3. Prepare Dictionaries\n    train_gold_dicts = get_data_dicts(train_gold_fold, phase='train')\n    # Fix the None crash by handling pseudo safely in helper\n    train_pseudo_dicts = get_data_dicts(None, pseudo_df, phase='train') \n    train_pseudo_only = [d for d in train_pseudo_dicts if d['source'] == 'pseudo']\n    \n    val_dicts = get_data_dicts(val_gold_fold, phase='valid')\n    \n    # 4. Create Datasets\n    # CacheDataset for Real Data (Fast RAM access)\n    ds_gold = CacheDataset(\n        data=train_gold_dicts, \n        transform=Compose([get_transforms('train'), ProcessMaskd(keys=[\"mask\"], is_pseudo=False)]),\n        cache_rate=CONFIG['CACHE_RATE'], num_workers=4\n    )\n    \n    # Standard Dataset for Pseudo (Stream from disk)\n    ds_pseudo = Dataset(\n        data=train_pseudo_only,\n        transform=Compose([get_transforms('train'), ProcessMaskd(keys=[\"mask\"], is_pseudo=True)])\n    )\n    \n    ds_val = CacheDataset(\n        data=val_dicts,\n        transform=Compose([get_transforms('valid'), ProcessMaskd(keys=[\"mask\"], is_pseudo=False)]),\n        cache_rate=1.0\n    )\n    \n    # 5. Create Loaders (SPEED OPTIMIZED)\n    # Added persistent_workers=True to fix the \"GPU Waiting\" issue\n    loader_gold = MonaiLoader(\n        ds_gold, \n        batch_size=CONFIG['REAL_BS'], \n        shuffle=True, \n        num_workers=4, \n        persistent_workers=True, \n        drop_last=True\n    )\n    \n    loader_pseudo = MonaiLoader(\n        ds_pseudo, \n        batch_size=CONFIG['PSEUDO_BS'], \n        shuffle=True, \n        num_workers=4, \n        persistent_workers=True, \n        drop_last=True\n    )\n    \n    loader_val = MonaiLoader(\n        ds_val, \n        batch_size=24, # Increased for faster validation\n        shuffle=False, \n        num_workers=4,\n        persistent_workers=True\n    )\n    \n    # 6. Setup Model & Opt\n    model = build_model().to(CONFIG['DEVICE'])\n    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['LR'], weight_decay=CONFIG['WEIGHT_DECAY'])\n    # Warmup Cosine Scheduler (Best for MaxViT)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1, eta_min=1e-6)\n    scaler = GradScaler()\n    loss_fn = HybridLoss()\n    \n    # Tracking Variables\n    best_dice = 0.0\n    best_metrics = {} # To save for final report\n    \n    # History for Local Plots\n    history = {\n        'train_loss': [], 'train_dice': [], \n        'val_dice': [], 'val_iou': [], 'val_hd': []\n    }\n    \n    # 7. Epoch Loop\n    for epoch in range(CONFIG['EPOCHS']):\n        # Train One Epoch\n        train_loss, train_dice = train_one_epoch(model, loader_gold, loader_pseudo, optimizer, loss_fn, scaler, epoch)\n        \n        # Validate One Epoch (Returns 3 metrics now)\n        val_dice, val_hd, val_iou = valid_one_epoch(model, loader_val, epoch)\n        \n        scheduler.step()\n        \n        # Update Local History\n        history['train_loss'].append(train_loss)\n        history['train_dice'].append(train_dice)\n        history['val_dice'].append(val_dice)\n        history['val_iou'].append(val_iou)\n        history['val_hd'].append(val_hd)\n        \n        # Log to WandB\n        wandb.log({\n            \"epoch\": epoch,\n            \"train/loss\": train_loss,\n            \"train/dice\": train_dice,\n            \"val/dice\": val_dice,\n            \"val/iou\": val_iou,\n            \"val/hd\": val_hd,\n            \"lr\": optimizer.param_groups[0]['lr']\n        })\n    \n        print(f\"Ep {epoch} | Loss: {train_loss:.4f} | TrDice: {train_dice:.3f} | ValDice: {val_dice:.4f} | ValIoU: {val_iou:.4f}\")\n        \n        # Save Best Model & Metrics\n        if val_dice > best_dice:\n            best_dice = val_dice\n            # Snapshot metrics for report\n            best_metrics = {\n                \"fold\": fold,\n                \"best_dice\": val_dice,\n                \"best_iou\": val_iou,\n                \"best_hd\": val_hd,\n                \"best_epoch\": epoch\n            }\n            torch.save(model.state_dict(), f\"MaxViT_Best_Fold_{fold}.pth\")\n            print(f\"  ‚≠ê New Best Dice! Saved.\")\n            \n    wandb.finish()\n    \n    # 8. Save Metrics to JSON (For Final Report Cell)\n    with open(f\"metrics_fold_{fold}.json\", \"w\") as f:\n        json.dump(best_metrics, f)\n    print(f\"‚úÖ Fold {fold} metrics saved to disk.\")\n\n    # 9. Generate Local Analytics Plot (Optional, if Cell 11 is defined)\n    try:\n        plot_training_analytics(history, fold)\n    except NameError:\n        print(\"‚ö†Ô∏è Analytics plot skipped (Cell 11 function not found).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:30:31.112536Z","iopub.execute_input":"2025-11-20T22:30:31.112774Z","execution_failed":"2025-11-20T22:42:03.619Z"}},"outputs":[{"name":"stdout","text":"\nüöÄ STARTING FOLD 0\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251120_223031-21ekr3rw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/alzhemer_segmentaion/Brain_SOTA_MaxViT_AnchorUT/runs/21ekr3rw' target=\"_blank\">MaxViT_Fold_0</a></strong> to <a href='https://wandb.ai/alzhemer_segmentaion/Brain_SOTA_MaxViT_AnchorUT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/alzhemer_segmentaion/Brain_SOTA_MaxViT_AnchorUT' target=\"_blank\">https://wandb.ai/alzhemer_segmentaion/Brain_SOTA_MaxViT_AnchorUT</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/alzhemer_segmentaion/Brain_SOTA_MaxViT_AnchorUT/runs/21ekr3rw' target=\"_blank\">https://wandb.ai/alzhemer_segmentaion/Brain_SOTA_MaxViT_AnchorUT/runs/21ekr3rw</a>"},"metadata":{}},{"name":"stderr","text":"Loading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [00:00<00:00, 231649.51it/s]\nLoading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 104596.11it/s]\n/tmp/ipykernel_360/2248091931.py:87: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train Ep 0:   0%|          | 0/776 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a160940a31f448a79f38334614b90831"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_360/4081194.py:21: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/usr/local/lib/python3.11/dist-packages/monai/losses/hausdorff_loss.py:171: UserWarning: single channel prediction, `include_background=False` ignored.\n  warnings.warn(\"single channel prediction, `include_background=False` ignored.\")\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Cell 10: Visualization\n# ==================================================================================\ndef visualize_results(model_path, val_loader, fold):\n    print(f\"üìä Visualizing Fold {fold}...\")\n    model = build_model()\n    model.load_state_dict(torch.load(model_path))\n    model.to(CONFIG['DEVICE'])\n    model.eval()\n    \n    batch = next(iter(val_loader))\n    images, masks = batch['image'].to(CONFIG['DEVICE']), batch['mask'].to(CONFIG['DEVICE'])\n    \n    with torch.no_grad():\n        preds = torch.sigmoid(model(images))\n        preds = (preds > 0.5).float()\n        \n    # Plot 5 samples\n    fig, axes = plt.subplots(5, 4, figsize=(15, 20))\n    for i in range(5):\n        if i >= len(images): break\n        \n        # Input\n        img_np = images[i, 0].cpu().numpy()\n        axes[i,0].imshow(img_np, cmap='gray')\n        axes[i,0].set_title(\"Input MRI\")\n        \n        # Truth\n        gt_np = masks[i, 0].cpu().numpy()\n        axes[i,1].imshow(gt_np, cmap='gray')\n        axes[i,1].set_title(\"Ground Truth\")\n        \n        # Pred\n        pred_np = preds[i, 0].cpu().numpy()\n        axes[i,2].imshow(pred_np, cmap='gray')\n        axes[i,2].set_title(f\"Prediction\")\n        \n        # Error Map (Red = FP, Blue = FN)\n        diff = pred_np - gt_np\n        axes[i,3].imshow(diff, cmap='coolwarm')\n        axes[i,3].set_title(\"Error Map (Red=FP, Blue=FN)\")\n        \n    plt.tight_layout()\n    plt.show()\n\n# To run visualization after training:\n# visualize_results(f\"MaxViT_Best_Fold_0.pth\", loader_val, 0)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-20T22:42:03.620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11: Advanced Training Analytics Plotting\n# ==================================================================================\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_training_analytics(history, fold):\n    # Set style\n    sns.set_style(\"darkgrid\")\n    plt.rcParams['font.size'] = 10\n    \n    epochs = range(len(history['train_loss']))\n    fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n    fig.suptitle(f'Fold {fold} Training Dynamics', fontsize=16, weight='bold')\n    \n    # 1. LOSS DYNAMICS\n    # Shows if the model is actually learning\n    axes[0,0].plot(epochs, history['train_loss'], label='Train Hybrid Loss', color='#FF5733', linewidth=2)\n    axes[0,0].set_title(\"üìâ Loss Convergence\", fontsize=12, weight='bold')\n    axes[0,0].set_xlabel(\"Epochs\")\n    axes[0,0].set_ylabel(\"Loss\")\n    axes[0,0].legend()\n    \n    # 2. ACCURACY METRICS\n    # Shows Dice and IoU together\n    axes[0,1].plot(epochs, history['val_dice'], label='Val Dice', color='#2E86C1', linewidth=2)\n    axes[0,1].plot(epochs, history['val_iou'], label='Val IoU', color='#28B463', linestyle='--')\n    axes[0,1].set_title(\"üéØ Accuracy (Overlap)\", fontsize=12, weight='bold')\n    axes[0,1].set_xlabel(\"Epochs\")\n    axes[0,1].set_ylabel(\"Score (0-1)\")\n    axes[0,1].legend()\n    \n    # 3. GENERALIZATION GAP (Train vs Val)\n    # CRITICAL: If Train (Red) is way higher than Val (Blue), you are overfitting (memorizing noise).\n    # Ideally, they should move up together.\n    # Note: We assume you logged 'train_dice' in history during Cell 9\n    if 'train_dice' in history:\n        axes[1,0].plot(epochs, history['train_dice'], label='Train Dice', color='#C0392B', linestyle=':')\n        axes[1,0].plot(epochs, history['val_dice'], label='Val Dice', color='#2E86C1', linewidth=2)\n        axes[1,0].set_title(\"üß† Generalization Gap (Train vs Val)\", fontsize=12, weight='bold')\n        axes[1,0].set_xlabel(\"Epochs\")\n        axes[1,0].set_ylabel(\"Dice Score\")\n        axes[1,0].legend()\n    else:\n        axes[1,0].text(0.5, 0.5, \"Train Dice not found in history\", ha='center')\n    \n    # 4. BOUNDARY QUALITY (Hausdorff)\n    # Shows if edges are getting sharper. Lower is better.\n    axes[1,1].plot(epochs, history['val_hd'], label='Val HD95', color='#884EA0', linewidth=2)\n    axes[1,1].set_title(\"üìè Edge Precision (Hausdorff Dist)\", fontsize=12, weight='bold')\n    axes[1,1].set_xlabel(\"Epochs\")\n    axes[1,1].set_ylabel(\"Distance (Pixels)\")\n    axes[1,1].legend()\n    axes[1,1].invert_yaxis() # Invert because lower is better\n    \n    plt.tight_layout()\n    plt.savefig(f\"analytics_fold_{fold}.png\", dpi=300)\n    plt.show()\n\n# Usage Example (Put this inside Cell 9 after the loop, or run manually):\nplot_training_analytics(history, fold)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-20T22:42:03.620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 12: Final Aggregate Report\n# ==================================================================================\nimport glob\nimport json\n\ndef generate_final_paper_report():\n    print(\"\\n\" + \"=\"*80)\n    print(\"üìÑ GENERATING FINAL CROSS-VALIDATION REPORT\")\n    print(\"=\"*80)\n    \n    # 1. Find all metric files\n    metric_files = glob.glob(\"metrics_fold_*.json\")\n    \n    if not metric_files:\n        print(\"‚ö†Ô∏è No metric files found! Did you complete any folds?\")\n        return\n    \n    results = []\n    for fpath in metric_files:\n        with open(fpath, 'r') as f:\n            results.append(json.load(f))\n            \n    # 2. Create DataFrame\n    df_res = pd.DataFrame(results).sort_values('fold').set_index('fold')\n    \n    # 3. Calculate Aggregate Stats\n    mean_dice = df_res['best_dice'].mean()\n    std_dice = df_res['best_dice'].std()\n    \n    mean_iou = df_res['best_iou'].mean()\n    std_iou = df_res['best_iou'].std()\n    \n    mean_hd = df_res['best_hd'].mean()\n    std_hd = df_res['best_hd'].std()\n    \n    # 4. Print detailed table\n    print(\"\\nüìä PER-FOLD PERFORMANCE:\")\n    print(\"-\" * 60)\n    print(df_res.to_string(float_format=\"{:.4f}\".format))\n    print(\"-\" * 60)\n    \n    # 5. Print Scientific Summary\n    report = f\"\"\"\n    üèÜ FINAL AGGREGATE RESULTS ({len(df_res)} Folds):\n    \n    üîπ DICE SCORE:       {mean_dice:.4f} ¬± {std_dice:.4f}  (Target: >0.90)\n    üîπ IOU SCORE:        {mean_iou:.4f}  ¬± {std_iou:.4f}\n    üîπ HAUSDORFF (95%):  {mean_hd:.4f}   ¬± {std_hd:.4f}   (Lower is better)\n    \n    ------------------------------------------------------------\n    CONCLUSION:\n    The model achieved a mean Dice score of {mean_dice:.4f} across {len(df_res)} folds.\n    The standard deviation of {std_dice:.4f} indicates {'STABLE' if std_dice < 0.015 else 'UNSTABLE'} performance.\n    \"\"\"\n    \n    print(report)\n    \n    # 6. Save to Text File (for your paper/report)\n    with open(\"final_sota_report.txt\", \"w\") as f:\n        f.write(report)\n        f.write(\"\\n\\nRaw Data:\\n\")\n        f.write(df_res.to_string())\n        \n    print(\"‚úÖ Report saved to 'final_sota_report.txt'\")\n\n# Run the report\ngenerate_final_paper_report()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-20T22:42:03.620Z"}},"outputs":[],"execution_count":null}]}