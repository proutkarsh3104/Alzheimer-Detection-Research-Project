{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13717847,"sourceType":"datasetVersion","datasetId":8727349},{"sourceId":13727681,"sourceType":"datasetVersion","datasetId":8733853},{"sourceId":13727859,"sourceType":"datasetVersion","datasetId":8733969},{"sourceId":13729238,"sourceType":"datasetVersion","datasetId":8734948},{"sourceId":13735051,"sourceType":"datasetVersion","datasetId":8739144}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Install Dependencies\n# ==================================================================================\n!pip install segmentation_models_pytorch wandb -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:34:31.962416Z","iopub.execute_input":"2025-11-14T06:34:31.962975Z","iopub.status.idle":"2025-11-14T06:35:47.741411Z","shell.execute_reply.started":"2025-11-14T06:34:31.962949Z","shell.execute_reply":"2025-11-14T06:35:47.740628Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 2: Import Libraries\n# ==================================================================================\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# PyTorch imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom torch.cuda.amp import GradScaler, autocast\n\n# Model, Augmentations, and Utilities\nimport segmentation_models_pytorch as smp\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import KFold, train_test_split\n\n# Experiment Tracking\nimport wandb\n\nprint(\"All libraries imported successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:35:50.266391Z","iopub.execute_input":"2025-11-14T06:35:50.266658Z","iopub.status.idle":"2025-11-14T06:36:01.618174Z","shell.execute_reply.started":"2025-11-14T06:35:50.266628Z","shell.execute_reply":"2025-11-14T06:36:01.617325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 3: W&B Login\n# ==================================================================================\nfrom kaggle_secrets import UserSecretsClient\ntry:\n    user_secrets = UserSecretsClient()\n    wandb_api_key = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=wandb_api_key)\n    print(\"âœ“ Logged in to W&B successfully!\")\nexcept:\n    wandb.login(anonymous='must')\n    print(\"âš  Using anonymous W&B login\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:01.619457Z","iopub.execute_input":"2025-11-14T06:36:01.620205Z","iopub.status.idle":"2025-11-14T06:36:09.887496Z","shell.execute_reply.started":"2025-11-14T06:36:01.620164Z","shell.execute_reply":"2025-11-14T06:36:09.886906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 4: Seeding for Reproducibility\n# ==================================================================================\ndef seed_everything(seed=42):\n    \"\"\"Set seeds for reproducibility\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(42)\nprint(\"âœ“ Random seeds set for reproducibility\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:23.146846Z","iopub.execute_input":"2025-11-14T06:36:23.147327Z","iopub.status.idle":"2025-11-14T06:36:23.158087Z","shell.execute_reply.started":"2025-11-14T06:36:23.147302Z","shell.execute_reply":"2025-11-14T06:36:23.157525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5: Configuration\n# ==================================================================================\nconfig = {\n    # ========== DATA PATHS ==========\n    # For baseline experiment, you only need the gold standard dataset\n    \"GOLD_STANDARD_PATH\": '/kaggle/input/200-gold-standard-adni/200_AD_CN_MCI_11112025/',\n    \"GOLD_METADATA\": '/kaggle/input/metadata/metadata.csv',\n    \n    # Pseudo-label paths (not used in baseline, but keep for later experiments)\n    \"PSEUDO_LABEL_PATH\": '/kaggle/input/bronze-new-standard-5300/PSEUDO_LABELS/',\n    \"PSEUDO_METADATA\": '/kaggle/input/bronze-new-standard-5300/PSEUDO_LABELS/metadata.csv',\n    \n    # ========== IMAGE SETTINGS ==========\n    \"IMG_HEIGHT\": 320,\n    \"IMG_WIDTH\": 320,\n    \n    # ========== MODEL ARCHITECTURE ==========\n    \"MODEL_ARCHITECTURE\": \"UnetPlusPlus\",\n    \"ENCODER\": 'efficientnet-b4',\n    \"PRETRAINED_WEIGHTS\": 'imagenet',\n    \n    # ========== TRAINING HYPERPARAMETERS ==========\n    \"BATCH_SIZE\": 32,\n    \"EPOCHS\": 150,\n    \"LEARNING_RATE\": 1e-4,\n    \"WEIGHT_DECAY\": 1e-5,\n    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"NUM_WORKERS\": 4,\n    \n    # ========== TRAINING STRATEGY ==========\n    \"PATIENCE\": 40,\n    \"USE_PSEUDO_LABELS\": True,  # â¬…ï¸ START WITH FALSE - Baseline experiment first!\n    \n    # ========== CROSS-VALIDATION ==========\n    \"N_FOLDS\": 5,\n    \"CURRENT_FOLD\": None,  # Will be set during training\n    \n    # ========== W&B CONFIGURATION ==========\n    \"WANDB_PROJECT\": \"Brain-Segmentation-eXP3\",  # Changed for baseline experiment\n    \"ENTITY\": \"alzhemer_segmentaion\",\n    \"RUN_NAME\": None,  # Will be set per fold\n}\n\nprint(f\"âœ“ Configuration loaded\")\nprint(f\"âœ“ Using device: {config['DEVICE']}\")\nprint(f\"âœ“ GPU Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"âœ“ GPU Name: {torch.cuda.get_device_name(0)}\")\n\n# ========== EXPERIMENT INFORMATION ==========\nprint(\"\\n\" + \"=\"*80)\nprint(\"ğŸ§ª EXPERIMENT: BASELINE (SUPERVISED LEARNING)\")\nprint(\"=\"*80)\nprint(f\"Training Strategy:\")\nprint(f\"  â€¢ Training:   ~160 gold standard images per fold\")\nprint(f\"  â€¢ Validation: ~40 gold standard images per fold\")\nprint(f\"  â€¢ Pseudo-labels: NOT USED (establishing baseline)\")\nprint(f\"  â€¢ Purpose: Establish baseline performance for comparison\")\nprint(f\"  â€¢ Expected Dice: ~0.88-0.92\")\nprint(\"=\"*80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:26.474151Z","iopub.execute_input":"2025-11-14T06:36:26.474794Z","iopub.status.idle":"2025-11-14T06:36:26.562207Z","shell.execute_reply.started":"2025-11-14T06:36:26.474768Z","shell.execute_reply":"2025-11-14T06:36:26.561524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6: Load and Prepare Data\n# ==================================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"LOADING DATA\")\nprint(\"=\"*80)\n\n# Load gold standard data (200 manually labeled images)\ngold_metadata = pd.read_csv(config['GOLD_METADATA'])\nprint(f\"\\nâœ“ Gold Standard Images: {len(gold_metadata)}\")\n\n# Load pseudo-labeled data (5000 images)\nif config['USE_PSEUDO_LABELS']:\n    pseudo_metadata = pd.read_csv(config['PSEUDO_METADATA'])\n    print(f\"âœ“ Pseudo-Labeled Images: {len(pseudo_metadata)}\")\n    print(f\"âœ“ Total Training Pool: {len(gold_metadata) + len(pseudo_metadata)}\")\nelse:\n    pseudo_metadata = None\n    print(\"âš  Training ONLY on Gold Standard (no pseudo-labels)\")\n\n# Add source identifier\ngold_metadata['source'] = 'gold'\nif pseudo_metadata is not None:\n    pseudo_metadata['source'] = 'pseudo'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:29.847923Z","iopub.execute_input":"2025-11-14T06:36:29.848488Z","iopub.status.idle":"2025-11-14T06:36:29.869209Z","shell.execute_reply.started":"2025-11-14T06:36:29.848459Z","shell.execute_reply":"2025-11-14T06:36:29.868433Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7: Data Augmentation Pipeline\n# ==================================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"AUGMENTATION PIPELINE\")\nprint(\"=\"*80)\n\n# Training augmentations - clinically informed\ntrain_augs = A.Compose([\n    A.PadIfNeeded(\n        min_height=config['IMG_HEIGHT'],\n        min_width=config['IMG_WIDTH'],\n        border_mode=cv2.BORDER_CONSTANT,\n    ),\n    A.Resize(height=config['IMG_HEIGHT'], width=config['IMG_WIDTH']),\n    \n    # Geometric transformations (simulate patient positioning)\n    A.Affine(\n        scale=(0.95, 1.05),\n        translate_percent=(-0.05, 0.05),\n        rotate=(-7, 7),\n        p=0.8\n    ),\n    \n    # Intensity augmentations (simulate scanner variations)\n    A.RandomBrightnessContrast(p=0.4),\n    A.GaussNoise(p=0.3),\n    A.CLAHE(p=0.5),\n    A.Sharpen(p=0.3),\n    \n    # Normalization and conversion\n    A.Normalize(mean=(0.5,), std=(0.5,)),\n    ToTensorV2(),\n])\n\n# Validation augmentations - no augmentation, only preprocessing\nval_augs = A.Compose([\n    A.PadIfNeeded(\n        min_height=config['IMG_HEIGHT'],\n        min_width=config['IMG_WIDTH'],\n        border_mode=cv2.BORDER_CONSTANT,\n    ),\n    A.Resize(height=config['IMG_HEIGHT'], width=config['IMG_WIDTH']),\n    A.Normalize(mean=(0.5,), std=(0.5,)),\n    ToTensorV2(),\n])\n\nprint(\"âœ“ Augmentation pipelines created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:32.002929Z","iopub.execute_input":"2025-11-14T06:36:32.003924Z","iopub.status.idle":"2025-11-14T06:36:32.016951Z","shell.execute_reply.started":"2025-11-14T06:36:32.003896Z","shell.execute_reply":"2025-11-14T06:36:32.016167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 8: Custom Dataset Class\n# ==================================================================================\nclass BrainMRIDataset(Dataset):\n    \"\"\"\n    Custom Dataset for Brain MRI Segmentation\n    Handles both gold standard and pseudo-labeled data\n    \"\"\"\n    def __init__(self, df, base_path, augmentations=None):\n        self.df = df.reset_index(drop=True)\n        self.base_path = base_path\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # Construct paths based on source\n        if row['source'] == 'gold':\n            image_path = os.path.join(self.base_path['gold'], 'images', row['image_id'])\n            mask_path = os.path.join(self.base_path['gold'], 'masks', row['mask_id'])\n        else:\n            image_path = os.path.join(self.base_path['pseudo'], 'images965', row['image_id'])\n            mask_path = os.path.join(self.base_path['pseudo'], 'masks965', row['mask_id'])\n        \n        # Read image and mask\n        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        \n        # Ensure shape consistency\n        if image.shape != mask.shape:\n            mask = cv2.resize(mask, (image.shape[1], image.shape[0]), \n                            interpolation=cv2.INTER_NEAREST)\n        \n        # Add channel dimension\n        image = np.expand_dims(image, axis=-1)\n        mask = np.expand_dims(mask, axis=-1)\n        \n        # Apply augmentations\n        if self.augmentations:\n            transformed = self.augmentations(image=image, mask=mask)\n            image = transformed['image']\n            mask = transformed['mask']\n        \n        # Convert mask to binary\n        mask = (mask / 255.0 > 0.5).float()\n        \n        return image, mask.permute(2, 0, 1)\n\nprint(\"âœ“ Custom Dataset class defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:35.470287Z","iopub.execute_input":"2025-11-14T06:36:35.470591Z","iopub.status.idle":"2025-11-14T06:36:35.478956Z","shell.execute_reply.started":"2025-11-14T06:36:35.470569Z","shell.execute_reply":"2025-11-14T06:36:35.477988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9: Loss Functions and Metrics\n# ==================================================================================\nclass TverskyLoss(nn.Module):\n    \"\"\"Tversky Loss - handles class imbalance\"\"\"\n    def __init__(self, alpha=0.7, beta=0.3, smooth=1e-6):\n        super(TverskyLoss, self).__init__()\n        self.alpha = alpha\n        self.beta = beta\n        self.smooth = smooth\n        \n    def forward(self, inputs, targets):\n        inputs = torch.sigmoid(inputs)\n        inputs, targets = inputs.view(-1), targets.view(-1)\n        \n        true_pos = (inputs * targets).sum()\n        false_neg = ((1 - inputs) * targets).sum()\n        false_pos = (inputs * (1 - targets)).sum()\n        \n        tversky_index = (true_pos + self.smooth) / (\n            true_pos + self.alpha * false_neg + self.beta * false_pos + self.smooth\n        )\n        return 1 - tversky_index\n\nclass FocalLoss(nn.Module):\n    \"\"\"Focal Loss - focuses on hard examples\"\"\"\n    def __init__(self, alpha=0.8, gamma=3.0, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n        \n    def forward(self, inputs, targets):\n        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-bce_loss)\n        focal_loss = self.alpha * (1 - pt)**self.gamma * bce_loss\n        return focal_loss.mean() if self.reduction == 'mean' else focal_loss\n\nclass WeightedFocalTverskyLoss(nn.Module):\n    \"\"\"Combined Focal + Tversky Loss\"\"\"\n    def __init__(self, focal_weight=0.6, tversky_weight=0.4):\n        super(WeightedFocalTverskyLoss, self).__init__()\n        self.focal_loss = FocalLoss()\n        self.tversky_loss = TverskyLoss()\n        self.focal_weight = focal_weight\n        self.tversky_weight = tversky_weight\n        \n    def forward(self, inputs, targets):\n        return (self.focal_weight * self.focal_loss(inputs, targets) + \n                self.tversky_weight * self.tversky_loss(inputs, targets))\n\nclass BCEFocalTverskyLoss(nn.Module):\n    \"\"\"Ultimate Combined Loss: BCE + Focal + Tversky\"\"\"\n    def __init__(self, bce_weight=0.3, focal_tversky_weight=0.7):\n        super(BCEFocalTverskyLoss, self).__init__()\n        self.bce_loss = nn.BCEWithLogitsLoss()\n        self.focal_tversky_loss = WeightedFocalTverskyLoss()\n        self.bce_weight = bce_weight\n        self.focal_tversky_weight = focal_tversky_weight\n        \n    def forward(self, inputs, targets):\n        bce = self.bce_loss(inputs, targets)\n        focal_tversky = self.focal_tversky_loss(inputs, targets)\n        return self.bce_weight * bce + self.focal_tversky_weight * focal_tversky\n\ndef dice_coef(y_pred, y_true, smooth=1):\n    \"\"\"Dice Coefficient - primary evaluation metric\"\"\"\n    y_pred_sig = torch.sigmoid(y_pred)\n    y_pred_bin = (y_pred_sig > 0.5).float()\n    \n    intersection = (y_pred_bin.view(-1) * y_true.view(-1)).sum()\n    return (2. * intersection + smooth) / (y_pred_bin.sum() + y_true.sum() + smooth)\n\ndef iou_score(y_pred, y_true, smooth=1):\n    \"\"\"IoU Score - additional metric\"\"\"\n    y_pred_sig = torch.sigmoid(y_pred)\n    y_pred_bin = (y_pred_sig > 0.5).float()\n    \n    intersection = (y_pred_bin.view(-1) * y_true.view(-1)).sum()\n    union = y_pred_bin.sum() + y_true.sum() - intersection\n    return (intersection + smooth) / (union + smooth)\n\nprint(\"âœ“ Loss functions and metrics defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:37.905876Z","iopub.execute_input":"2025-11-14T06:36:37.906216Z","iopub.status.idle":"2025-11-14T06:36:37.924969Z","shell.execute_reply.started":"2025-11-14T06:36:37.906163Z","shell.execute_reply":"2025-11-14T06:36:37.924057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #Cell 10: Model Creation Function\n# ==================================================================================\ndef create_model(config):\n    \"\"\"Create U-Net++ model with specified encoder\"\"\"\n    model = smp.UnetPlusPlus(\n        encoder_name=config['ENCODER'],\n        encoder_weights=config['PRETRAINED_WEIGHTS'],\n        in_channels=1,\n        classes=1\n    ).to(config['DEVICE'])\n    \n    # Multi-GPU support\n    if torch.cuda.device_count() > 1:\n        print(f\"âœ“ Using {torch.cuda.device_count()} GPUs!\")\n        model = nn.DataParallel(model)\n    \n    return model\n\nprint(\"âœ“ Model creation function defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:42.071620Z","iopub.execute_input":"2025-11-14T06:36:42.071889Z","iopub.status.idle":"2025-11-14T06:36:42.077276Z","shell.execute_reply.started":"2025-11-14T06:36:42.071869Z","shell.execute_reply":"2025-11-14T06:36:42.076435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11: Training Function\n# ==================================================================================\ndef train_one_epoch(model, train_loader, optimizer, loss_fn, scaler, scheduler, device):\n    \"\"\"Train for one epoch\"\"\"\n    model.train()\n    total_loss = 0.0\n    total_dice = 0.0\n    total_iou = 0.0\n    \n    loop = tqdm(train_loader, desc=\"Training\", leave=False)\n    \n    for images, masks in loop:\n        images = images.to(device)\n        masks = masks.to(device)\n        \n        optimizer.zero_grad(set_to_none=True)\n        \n        with autocast():\n            outputs = model(images)\n            loss = loss_fn(outputs, masks)\n        \n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        total_dice += dice_coef(outputs, masks).item()\n        total_iou += iou_score(outputs, masks).item()\n        \n        loop.set_postfix({\n            \"loss\": f\"{loss.item():.4f}\",\n            \"dice\": f\"{dice_coef(outputs, masks).item():.4f}\",\n            \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n        })\n    \n    return {\n        'loss': total_loss / len(train_loader),\n        'dice': total_dice / len(train_loader),\n        'iou': total_iou / len(train_loader)\n    }\n\ndef validate(model, val_loader, loss_fn, device):\n    \"\"\"Validate the model\"\"\"\n    model.eval()\n    total_loss = 0.0\n    total_dice = 0.0\n    total_iou = 0.0\n    \n    with torch.no_grad():\n        loop = tqdm(val_loader, desc=\"Validation\", leave=False)\n        \n        for images, masks in loop:\n            images = images.to(device)\n            masks = masks.to(device)\n            \n            with autocast():\n                outputs = model(images)\n                loss = loss_fn(outputs, masks)\n            \n            total_loss += loss.item()\n            total_dice += dice_coef(outputs, masks).item()\n            total_iou += iou_score(outputs, masks).item()\n            \n            loop.set_postfix({\n                \"loss\": f\"{loss.item():.4f}\",\n                \"dice\": f\"{dice_coef(outputs, masks).item():.4f}\"\n            })\n    \n    return {\n        'loss': total_loss / len(val_loader),\n        'dice': total_dice / len(val_loader),\n        'iou': total_iou / len(val_loader)\n    }\n\nprint(\"âœ“ Training and validation functions defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:45.219701Z","iopub.execute_input":"2025-11-14T06:36:45.220427Z","iopub.status.idle":"2025-11-14T06:36:45.229414Z","shell.execute_reply.started":"2025-11-14T06:36:45.220400Z","shell.execute_reply":"2025-11-14T06:36:45.228679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 12: K-Fold Cross-Validation Training\n# ==================================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING K-FOLD CROSS-VALIDATION\")\nprint(\"=\"*80)\n\n# Prepare K-Fold splits on gold standard data ONLY\nkfold = KFold(n_splits=config['N_FOLDS'], shuffle=True, random_state=42)\nfold_results = []\n\n# Base paths for datasets\nbase_path = {\n    'gold': config['GOLD_STANDARD_PATH'],\n    'pseudo': config['PSEUDO_LABEL_PATH']\n}\n\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(gold_metadata), 1):\n    print(f\"\\n{'='*80}\")\n    print(f\"FOLD {fold}/{config['N_FOLDS']}\")\n    print(f\"{'='*80}\")\n    \n    config['CURRENT_FOLD'] = fold\n    config['RUN_NAME'] = f\"Fold{fold}_EfficientNetB4_320px_SemiSupervised\"\n    \n    # Initialize W&B for this fold\n    wandb.init(\n        project=config['WANDB_PROJECT'],\n        entity=config['ENTITY'],\n        config=config,\n        name=config['RUN_NAME'],\n        reinit=True\n    )\n    \n    # Split gold standard data\n    train_gold = gold_metadata.iloc[train_idx].copy()\n    val_gold = gold_metadata.iloc[val_idx].copy()\n    \n    print(f\"\\nğŸ“Š Data Split:\")\n    print(f\"  Gold Standard Training: {len(train_gold)}\")\n    print(f\"  Gold Standard Validation: {len(val_gold)}\")\n    \n    # Combine with pseudo-labeled data for training\n    if config['USE_PSEUDO_LABELS']:\n        train_combined = pd.concat([train_gold, pseudo_metadata], ignore_index=True)\n        print(f\"  Pseudo-Labeled Training: {len(pseudo_metadata)}\")\n        print(f\"  Total Training: {len(train_combined)}\")\n    else:\n        train_combined = train_gold\n        print(f\"  Total Training: {len(train_combined)}\")\n    \n    # Create datasets and dataloaders\n    train_dataset = BrainMRIDataset(train_combined, base_path, augmentations=train_augs)\n    val_dataset = BrainMRIDataset(val_gold, base_path, augmentations=val_augs)\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['BATCH_SIZE'],\n        shuffle=True,\n        num_workers=config['NUM_WORKERS'],\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config['BATCH_SIZE'],\n        shuffle=False,\n        num_workers=config['NUM_WORKERS'],\n        pin_memory=True\n    )\n    \n    # Create model, optimizer, scheduler, loss\n    model = create_model(config)\n    loss_fn = BCEFocalTverskyLoss()\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=config['LEARNING_RATE'],\n        weight_decay=config['WEIGHT_DECAY']\n    )\n    \n    scheduler = OneCycleLR(\n        optimizer,\n        max_lr=config['LEARNING_RATE'],\n        epochs=config['EPOCHS'],\n        steps_per_epoch=len(train_loader),\n        pct_start=0.1,\n        div_factor=10,\n        final_div_factor=100\n    )\n    \n    scaler = GradScaler()\n    \n    # Training loop\n    best_val_dice = 0.0\n    patience_counter = 0\n    history = {\n        'train_loss': [], 'val_loss': [],\n        'train_dice': [], 'val_dice': [],\n        'train_iou': [], 'val_iou': []\n    }\n    \n    print(f\"\\nğŸš€ Starting Training for Fold {fold}...\")\n    \n    for epoch in range(config['EPOCHS']):\n        print(f\"\\nEpoch {epoch+1}/{config['EPOCHS']}\")\n        \n        # Train\n        train_metrics = train_one_epoch(\n            model, train_loader, optimizer, loss_fn, scaler, scheduler, config['DEVICE']\n        )\n        \n        # Validate\n        val_metrics = validate(model, val_loader, loss_fn, config['DEVICE'])\n        \n        # Store history\n        history['train_loss'].append(train_metrics['loss'])\n        history['train_dice'].append(train_metrics['dice'])\n        history['train_iou'].append(train_metrics['iou'])\n        history['val_loss'].append(val_metrics['loss'])\n        history['val_dice'].append(val_metrics['dice'])\n        history['val_iou'].append(val_metrics['iou'])\n        \n        # Log to W&B\n        wandb.log({\n            \"fold\": fold,\n            \"epoch\": epoch + 1,\n            \"train/loss\": train_metrics['loss'],\n            \"train/dice\": train_metrics['dice'],\n            \"train/iou\": train_metrics['iou'],\n            \"val/loss\": val_metrics['loss'],\n            \"val/dice\": val_metrics['dice'],\n            \"val/iou\": val_metrics['iou'],\n            \"learning_rate\": scheduler.get_last_lr()[0]\n        })\n        \n        # Print epoch summary\n        print(f\"  Train - Loss: {train_metrics['loss']:.4f}, \"\n              f\"Dice: {train_metrics['dice']:.4f}, IoU: {train_metrics['iou']:.4f}\")\n        print(f\"  Val   - Loss: {val_metrics['loss']:.4f}, \"\n              f\"Dice: {val_metrics['dice']:.4f}, IoU: {val_metrics['iou']:.4f}\")\n        \n        # Log predictions every 10 epochs\n        if (epoch + 1) % 10 == 0:\n            sample_images, sample_masks = next(iter(val_loader))\n            sample_images = sample_images.to(config['DEVICE'])\n            sample_masks = sample_masks.to(config['DEVICE'])\n            \n            model.eval()\n            with torch.no_grad(), autocast():\n                preds_raw = model(sample_images)\n                probs = torch.sigmoid(preds_raw)\n                preds = (probs > 0.5).float()\n            \n            log_images = []\n            for i in range(min(4, config[\"BATCH_SIZE\"])):\n                comparison_img = torch.cat([\n                    sample_images[i],\n                    sample_masks[i],\n                    preds[i]\n                ], dim=2)\n                \n                log_images.append(\n                    wandb.Image(\n                        comparison_img,\n                        caption=f\"Fold {fold}, Epoch {epoch+1}: Input | GT | Prediction\"\n                    )\n                )\n            \n            wandb.log({\"val/predictions\": log_images}, commit=False)\n        \n        # Save best model\n        if val_metrics['dice'] > best_val_dice:\n            best_val_dice = val_metrics['dice']\n            model_state = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n            torch.save(model_state, f\"best_model_fold{fold}.pth\")\n            print(f\"  âœ“ Model saved! Best Val Dice: {best_val_dice:.4f}\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            \n        # Early stopping\n        if patience_counter >= config['PATIENCE']:\n            print(f\"\\nâš  Early stopping triggered after {patience_counter} epochs without improvement\")\n            break\n    \n    # Store fold results\n    fold_results.append({\n        'fold': fold,\n        'best_val_dice': best_val_dice,\n        'best_val_loss': min(history['val_loss']),\n        'final_train_dice': history['train_dice'][-1],\n        'final_val_dice': history['val_dice'][-1]\n    })\n    \n    # Log final fold summary\n    wandb.log({\n        f\"fold{fold}/best_val_dice\": best_val_dice,\n        f\"fold{fold}/best_val_loss\": min(history['val_loss'])\n    })\n    \n    # Finish W&B run for this fold\n    wandb.finish()\n    \n    print(f\"\\nâœ“ Fold {fold} Complete - Best Val Dice: {best_val_dice:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:36:50.092376Z","iopub.execute_input":"2025-11-14T06:36:50.093016Z","iopub.status.idle":"2025-11-14T07:43:57.372536Z","shell.execute_reply.started":"2025-11-14T06:36:50.092982Z","shell.execute_reply":"2025-11-14T07:43:57.371734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 13: Cross-Validation Results Summary\n# ==================================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"K-FOLD CROSS-VALIDATION RESULTS\")\nprint(\"=\"*80)\n\nresults_df = pd.DataFrame(fold_results)\nprint(\"\\nğŸ“Š Individual Fold Results:\")\nprint(results_df.to_string(index=False))\n\nprint(f\"\\nğŸ“ˆ Summary Statistics:\")\nprint(f\"  Mean Val Dice: {results_df['best_val_dice'].mean():.4f} Â± {results_df['best_val_dice'].std():.4f}\")\nprint(f\"  Min Val Dice:  {results_df['best_val_dice'].min():.4f}\")\nprint(f\"  Max Val Dice:  {results_df['best_val_dice'].max():.4f}\")\n\n# Save results\nresults_df.to_csv('kfold_cv_results.csv', index=False)\nprint(f\"\\nâœ“ Results saved to 'kfold_cv_results.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:44:11.072023Z","iopub.execute_input":"2025-11-14T07:44:11.072730Z","iopub.status.idle":"2025-11-14T07:44:11.097330Z","shell.execute_reply.started":"2025-11-14T07:44:11.072683Z","shell.execute_reply":"2025-11-14T07:44:11.096528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 14: Visualization - Training Curves\n# ==================================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"VISUALIZING TRAINING CURVES\")\nprint(\"=\"*80)\n\n# Note: This will show the last fold's training curves\n# For production, you'd want to save and plot all folds\n\nplt.style.use('seaborn-v0_8-darkgrid')\nfig, axes = plt.subplots(2, 2, figsize=(18, 12))\n\nepochs_ran = range(1, len(history['train_loss']) + 1)\n\n# Plot 1: Loss\naxes[0, 0].plot(epochs_ran, history['train_loss'], 'b-o', label='Training Loss', alpha=0.7)\naxes[0, 0].plot(epochs_ran, history['val_loss'], 'r-o', label='Validation Loss', alpha=0.7)\naxes[0, 0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\naxes[0, 0].set_xlabel('Epochs', fontsize=12)\naxes[0, 0].set_ylabel('Loss', fontsize=12)\naxes[0, 0].legend(fontsize=11)\naxes[0, 0].grid(True, alpha=0.3)\n\n# Plot 2: Dice Coefficient\naxes[0, 1].plot(epochs_ran, history['train_dice'], 'b-o', label='Training Dice', alpha=0.7)\naxes[0, 1].plot(epochs_ran, history['val_dice'], 'r-o', label='Validation Dice', alpha=0.7)\naxes[0, 1].set_title('Training & Validation Dice Coefficient', fontsize=14, fontweight='bold')\naxes[0, 1].set_xlabel('Epochs', fontsize=12)\naxes[0, 1].set_ylabel('Dice Coefficient', fontsize=12)\naxes[0, 1].legend(fontsize=11)\naxes[0, 1].grid(True, alpha=0.3)\n\n# Plot 3: IoU Score\naxes[1, 0].plot(epochs_ran, history['train_iou'], 'b-o', label='Training IoU', alpha=0.7)\naxes[1, 0].plot(epochs_ran, history['val_iou'], 'r-o', label='Validation IoU', alpha=0.7)\naxes[1, 0].set_title('Training & Validation IoU Score', fontsize=14, fontweight='bold')\naxes[1, 0].set_xlabel('Epochs', fontsize=12)\naxes[1, 0].set_ylabel('IoU Score', fontsize=12)\naxes[1, 0].legend(fontsize=11)\naxes[1, 0].grid(True, alpha=0.3)\n\n# Plot 4: Cross-Validation Summary\nfold_numbers = results_df['fold'].values\nfold_dice_scores = results_df['best_val_dice'].values\naxes[1, 1].bar(fold_numbers, fold_dice_scores, alpha=0.7, color='steelblue', edgecolor='black')\naxes[1, 1].axhline(y=fold_dice_scores.mean(), color='red', linestyle='--', \n                   label=f'Mean: {fold_dice_scores.mean():.4f}', linewidth=2)\naxes[1, 1].set_title('Best Validation Dice per Fold', fontsize=14, fontweight='bold')\naxes[1, 1].set_xlabel('Fold', fontsize=12)\naxes[1, 1].set_ylabel('Dice Coefficient', fontsize=12)\naxes[1, 1].set_xticks(fold_numbers)\naxes[1, 1].legend(fontsize=11)\naxes[1, 1].grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Training curves saved as 'training_curves.png'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:44:21.047811Z","iopub.execute_input":"2025-11-14T07:44:21.048078Z","iopub.status.idle":"2025-11-14T07:44:23.779563Z","shell.execute_reply.started":"2025-11-14T07:44:21.048059Z","shell.execute_reply":"2025-11-14T07:44:23.778654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 15: Test Best Model from Best Fold\n# ==================================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"TESTING BEST MODEL\")\nprint(\"=\"*80)\n\n# Find best fold\nbest_fold_idx = results_df['best_val_dice'].idxmax()\nbest_fold = results_df.loc[best_fold_idx, 'fold']\nbest_dice = results_df.loc[best_fold_idx, 'best_val_dice']\n\nprint(f\"\\nğŸ† Best Fold: {best_fold} (Val Dice: {best_dice:.4f})\")\n\n# Load best model\nprint(f\"\\nğŸ“‚ Loading model from Fold {best_fold}...\")\nbest_model = create_model(config)\nbest_model_state = torch.load(f\"best_model_fold{best_fold}.pth\")\nif isinstance(best_model, nn.DataParallel):\n    best_model.module.load_state_dict(best_model_state)\nelse:\n    best_model.load_state_dict(best_model_state)\nbest_model.eval()\nprint(\"âœ“ Model loaded successfully\")\n\n# Create test set from validation fold of best model\n_, test_idx = list(kfold.split(gold_metadata))[best_fold - 1]\ntest_gold = gold_metadata.iloc[test_idx].copy()\n\nprint(f\"\\nğŸ“Š Test Set: {len(test_gold)} images (from Fold {best_fold} validation)\")\n\ntest_dataset = BrainMRIDataset(test_gold, base_path, augmentations=val_augs)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=config['BATCH_SIZE'],\n    shuffle=False,\n    num_workers=config['NUM_WORKERS'],\n    pin_memory=True\n)\n\n# Test with TTA (Test-Time Augmentation)\nprint(\"\\nğŸ§ª Testing with Test-Time Augmentation...\")\ntest_loss = 0.0\ntest_dice = 0.0\ntest_iou = 0.0\nloss_fn = BCEFocalTverskyLoss()\n\nwith torch.no_grad():\n    loop = tqdm(test_loader, desc=\"Testing\")\n    for images, masks in loop:\n        images = images.to(config['DEVICE'])\n        masks = masks.to(config['DEVICE'])\n        \n        with autocast():\n            # Original prediction\n            outputs_original = best_model(images)\n            \n            # Flipped prediction\n            flipped_images = torch.flip(images, [3])\n            outputs_flipped = best_model(flipped_images)\n            outputs_flipped = torch.flip(outputs_flipped, [3])\n            \n            # Average predictions (TTA)\n            outputs = (outputs_original + outputs_flipped) / 2.0\n        \n        loss = loss_fn(outputs, masks)\n        test_loss += loss.item()\n        test_dice += dice_coef(outputs, masks).item()\n        test_iou += iou_score(outputs, masks).item()\n        \n        loop.set_postfix({\n            \"loss\": f\"{loss.item():.4f}\",\n            \"dice\": f\"{dice_coef(outputs, masks).item():.4f}\"\n        })\n\navg_test_loss = test_loss / len(test_loader)\navg_test_dice = test_dice / len(test_loader)\navg_test_iou = test_iou / len(test_loader)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL TEST RESULTS (with TTA)\")\nprint(\"=\"*80)\nprint(f\"  Test Loss: {avg_test_loss:.4f}\")\nprint(f\"  Test Dice: {avg_test_dice:.4f}\")\nprint(f\"  Test IoU:  {avg_test_iou:.4f}\")\nprint(\"=\"*80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:44:37.205547Z","iopub.execute_input":"2025-11-14T07:44:37.206145Z","iopub.status.idle":"2025-11-14T07:44:38.844100Z","shell.execute_reply.started":"2025-11-14T07:44:37.206123Z","shell.execute_reply":"2025-11-14T07:44:38.843351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 16: Visualize Sample Predictions\n# ==================================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"VISUALIZING SAMPLE PREDICTIONS\")\nprint(\"=\"*80)\n\nnum_samples = 10\nindices = np.random.choice(range(len(test_dataset)), \n                          min(num_samples, len(test_dataset)), \n                          replace=False)\n\nbest_model.eval()\nfig, axes = plt.subplots(num_samples, 4, figsize=(20, num_samples*5))\n\nwith torch.no_grad():\n    for plot_idx, data_idx in enumerate(indices):\n        img_tensor, gt_tensor = test_dataset[data_idx]\n        img_input = img_tensor.unsqueeze(0).to(config['DEVICE'])\n        \n        # TTA prediction\n        with autocast():\n            outputs_original = torch.sigmoid(best_model(img_input))\n            flipped_images = torch.flip(img_input, [3])\n            outputs_flipped = torch.sigmoid(best_model(flipped_images))\n            outputs_flipped = torch.flip(outputs_flipped, [3])\n            final_prob = (outputs_original + outputs_flipped) / 2.0\n        \n        pred_mask = (final_prob > 0.5).cpu().numpy().squeeze()\n        img_np = img_tensor.numpy().squeeze()\n        gt_np = gt_tensor.numpy().squeeze()\n        \n        # Overlay visualization\n        overlay = cv2.cvtColor((img_np * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n        overlay[pred_mask > 0.5] = [255, 0, 0]  # Red for predictions\n        overlay[gt_np > 0.5] = [0, 255, 0]  # Green for ground truth\n        \n        # Calculate metrics for this sample\n        sample_dice = dice_coef(\n            torch.from_numpy(pred_mask).unsqueeze(0).unsqueeze(0),\n            torch.from_numpy(gt_np).unsqueeze(0).unsqueeze(0)\n        ).item()\n        \n        # Plot\n        if num_samples == 1:\n            ax = [axes]\n        else:\n            ax = axes[plot_idx]\n        \n        ax[0].imshow(img_np, cmap='gray')\n        ax[0].set_title(f'Input Image {plot_idx+1}', fontsize=12)\n        ax[0].axis('off')\n        \n        ax[1].imshow(gt_np, cmap='gray')\n        ax[1].set_title('Ground Truth', fontsize=12)\n        ax[1].axis('off')\n        \n        ax[2].imshow(pred_mask, cmap='gray')\n        ax[2].set_title(f'Prediction (Dice: {sample_dice:.3f})', fontsize=12)\n        ax[2].axis('off')\n        \n        ax[3].imshow(overlay)\n        ax[3].set_title('Overlay (Red=Pred, Green=GT)', fontsize=12)\n        ax[3].axis('off')\n\nplt.tight_layout()\nplt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ“ Sample predictions saved as 'sample_predictions.png'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:44:48.461930Z","iopub.execute_input":"2025-11-14T07:44:48.462659Z","iopub.status.idle":"2025-11-14T07:45:04.339244Z","shell.execute_reply.started":"2025-11-14T07:44:48.462629Z","shell.execute_reply":"2025-11-14T07:45:04.338362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 17: Final Summary Report\n# ==================================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL SUMMARY REPORT\")\nprint(\"=\"*80)\n\nsummary_report = f\"\"\"\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘                   BRAIN SEGMENTATION - FINAL REPORT                        â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nğŸ“Š DATASET INFORMATION:\n   â€¢ Gold Standard (Manual Labels):  {len(gold_metadata)} images\n   â€¢ Pseudo-Labels (Used in Training): {len(pseudo_metadata) if pseudo_metadata is not None else 0} images\n   â€¢ Total Training Pool:              {len(gold_metadata) + (len(pseudo_metadata) if pseudo_metadata is not None else 0)} images\n\nğŸ—ï¸ MODEL ARCHITECTURE:\n   â€¢ Architecture:  {config['MODEL_ARCHITECTURE']}\n   â€¢ Encoder:       {config['ENCODER']}\n   â€¢ Input Size:    {config['IMG_HEIGHT']}x{config['IMG_WIDTH']}\n   â€¢ Loss Function: BCE + Focal + Tversky (Weighted Combination)\n\nğŸ”¬ CROSS-VALIDATION RESULTS ({config['N_FOLDS']}-Fold CV on Gold Standard):\n   â€¢ Mean Dice Score:  {results_df['best_val_dice'].mean():.4f} Â± {results_df['best_val_dice'].std():.4f}\n   â€¢ Min Dice Score:   {results_df['best_val_dice'].min():.4f} (Fold {results_df.loc[results_df['best_val_dice'].idxmin(), 'fold']})\n   â€¢ Max Dice Score:   {results_df['best_val_dice'].max():.4f} (Fold {results_df.loc[results_df['best_val_dice'].idxmax(), 'fold']})\n\nğŸ† BEST MODEL (Fold {best_fold}):\n   â€¢ Validation Dice:  {best_dice:.4f}\n   â€¢ Test Dice (TTA):  {avg_test_dice:.4f}\n   â€¢ Test IoU (TTA):   {avg_test_iou:.4f}\n   â€¢ Test Loss:        {avg_test_loss:.4f}\n\nâœ… VALIDATION STRATEGY:\n   âœ“ Proper train/val/test split on GOLD STANDARD data only\n   âœ“ Pseudo-labels used only for training (not evaluation)\n   âœ“ K-Fold Cross-Validation for robust performance estimation\n   âœ“ Test-Time Augmentation for final predictions\n   âœ“ No data leakage between folds\n\nğŸ“ NOTES:\n   â€¢ All evaluation metrics are calculated on manually labeled gold standard data\n   â€¢ Pseudo-labeled data was used to augment training but NOT for evaluation\n   â€¢ This approach provides a realistic estimate of model performance\n   â€¢ Cross-validation ensures robustness across different data splits\n\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\"\"\"\n\nprint(summary_report)\n\n# Save report\nwith open('final_report.txt', 'w') as f:\n    f.write(summary_report)\n\nprint(\"\\nâœ“ Full report saved to 'final_report.txt'\")\nprint(\"\\n\" + \"=\"*80)\nprint(\"âœ… ALL EXPERIMENTS COMPLETE!\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:45:41.065954Z","iopub.execute_input":"2025-11-14T07:45:41.066601Z","iopub.status.idle":"2025-11-14T07:45:41.075398Z","shell.execute_reply.started":"2025-11-14T07:45:41.066576Z","shell.execute_reply":"2025-11-14T07:45:41.074725Z"}},"outputs":[],"execution_count":null}]}